# Easy first simulation for our symmetric mixture of Gaussians model
library(mvtnorm)
library(dplyr)
library(magrittr)

# true model - Mb = 2 for the single association cases, otherwise Mb = 1
piList <- list(c(0.82), c(0.02, 0.02), c(0.02, 0.02), c(0.1))
muList <- list(matrix(data=0, nrow=2, ncol=1), matrix(data=c(0, 2, 0, 4), nrow=2),
               matrix(data=c(2, 0, 4, 0), nrow=2), matrix(data=c(6, 6), nrow=2))
n <- 200000

set.seed(0)
Z0 <- rmvnorm(n=n * piList[[1]], mean=c(0, 0), sigma=diag(2))
Z1_m1 <- rbind(rmvnorm(n=n * piList[[2]][1] / 2, mean=c(0, muList[[2]][2, 1]), sigma=diag(2)),
              rmvnorm(n=n * piList[[2]][1] / 2, mean=c(0, -muList[[2]][2, 1]), sigma=diag(2)))
Z1_m2 <- rbind(rmvnorm(n=n * piList[[2]][2] / 2, mean=c(0, muList[[2]][2, 2]), sigma=diag(2)),
               rmvnorm(n=n * piList[[2]][2] / 2, mean=c(0, -muList[[2]][2, 2]), sigma=diag(2)))
Z2_m1 <- rbind(rmvnorm(n=n * piList[[3]][1] / 2, mean=c(muList[[3]][1, 1], 0), sigma=diag(2)),
               rmvnorm(n=n * piList[[3]][1] / 2, mean=c(-muList[[3]][1, 1], 0), sigma=diag(2)))
Z2_m2 <- rbind(rmvnorm(n=n * piList[[3]][2] / 2, mean=c(muList[[3]][1, 2], 0), sigma=diag(2)),
               rmvnorm(n=n * piList[[3]][2] / 2, mean=c(-muList[[3]][1, 2], 0), sigma=diag(2)))
Z3 <- rbind(rmvnorm(n=n * piList[[4]][1] / 4, mean=c(muList[[4]][1, 1], muList[[4]][2, 1]), sigma=diag(2)),
            rmvnorm(n=n * piList[[4]][1] / 4, mean=c(muList[[4]][1, 1], -muList[[4]][2, 1]), sigma=diag(2)),
            rmvnorm(n=n * piList[[4]][1] / 4, mean=c(-muList[[4]][1, 1], muList[[4]][2, 1]), sigma=diag(2)),
            rmvnorm(n=n * piList[[4]][1] / 4, mean=c(-muList[[4]][1, 1], -muList[[4]][2, 1]), sigma=diag(2)))
allZ <- rbind(Z0, Z1_m1, Z1_m2, Z2_m1, Z2_m2, Z3)
testStats <- allZ

apply(Z0, 2, mean)
apply(abs(Z1_m1), 2, mean)
apply(abs(Z1_m2), 2, mean)
apply(abs(Z2_m1), 2, mean)
apply(abs(Z2_m2), 2, mean)
apply(abs(Z3), 2, mean)


# apply this function to calculate the density
calc_dens_ind_2d <- function(x, Zmat) {
  # right now, only for 2 or 3 dimensions
  dnorm(Zmat[, 1], mean=x[1], sd=1) * dnorm(Zmat[, 2], mean=x[2], sd=1)
}
calc_dens_ind_3d <- function(x, Zmat) {
  # right now, only for 2 or 3 dimensions
  dnorm(Zmat[, 1], mean=x[1], sd=1) * dnorm(Zmat[, 2], mean=x[2], sd=1) * dnorm(Zmat[, 2], mean=x[3], sd=1)
}

# give it the real parameters - works
initMuList <- muList
initPiList <- piList
outputReal <- symm_fit_ind(testStats = allZ, initMuList = initMuList, initPiList = initPiList, eps=10^(-5))
# check for incongruous
incongruous1 <- check_incongruous(zMatrix = allZ[1:200000, ], lfdrVec = outputReal$lfdrResults[1:200000])

# give it a harder test
set.seed(1)
maxMeans <- matrix(data=runif(n=2, min=4, max=8), nrow=2, ncol=1)
initMuList <- list(matrix(data=0, nrow=2, ncol=1), matrix(data=runif(n=4, min=0, max=min(maxMeans)), nrow=2, ncol=2),
                   matrix(data=runif(n=4, min=0, max=min(maxMeans)), nrow=2, ncol=2), maxMeans)
initMuList
initPiList <- list(c(0.82), c(0.02, 0.02),c(0.02, 0.02), c(0.1))

# run it - takes like 177 iterations but does converge to about the right thing
outputHard <- symm_fit_ind(testStats = allZ, initMuList = initMuList, initPiList = initPiList, eps=10^(-5))
incongruous2 <- check_incongruous(zMatrix = allZ, lfdrVec = outputHard$lfdrResults)

# function to do our method
# testStats is J*K matrix of test statistics
# initMuList is list of length K - 1, where the bth element of the list is a K*Mb matrix with the
# means for bl = b
# initPiList is a list of length K, where the bth element of the list is an Mb*1 vector holding
# the probabilities for bl = b
symm_fit_ind <- function(testStats, initMuList, initPiList, eps = 10^(-5)) {

  J <- nrow(testStats)
  # number of dimensions
  K <- ncol(testStats)
  B <- 2^K - 1
  # number of hl configurations - 1
  L <- 3^K - 1
  # make all configurations
  Hmat <- expand.grid(rep(list(-1:1), K))
  # attach the bl
  blVec <- rep(0, nrow(Hmat))
  slVec <- rep(0, nrow(Hmat))
  for (k_it in K:1) {
    blVec <- blVec + 2^(K - k_it) * abs(Hmat[, k_it])
    slVec <- slVec + abs(Hmat[, k_it])
  }
  # sort Hmat
  Hmat <- Hmat %>% mutate(bl = blVec) %>%
    mutate(sl = slVec) %>%
    arrange(blVec, Var1, Var2) %>%
    mutate(l = 0:(nrow(.) - 1))

  # initialize
  # the muInfo and piInfo are lists that hold the information in a more compact manner.
  # the allMu and allPi are matrices that repeat the information so the calculations can be performed faster.
  muInfo <- initMuList
  piInfo <- initPiList
  oldParams <- c(unlist(piInfo), unlist(muInfo))
  MbVec <- sapply(piInfo, FUN=length)

  # run until convergence
  diffParams <- 10
  iter <- 0
  while (diffParams > eps) {

    #####################################################
    # first, update allPi and allMu with the new parameter values

    # allPi holds the probabilities of each configuration (c 1), the bl of that
    # configuration (c 2), the sl of that configuration (c3), the m of that configuration (c 4),
    # and the l of that configuration (c 5),

    # number of rows in piMat is L if Mb = 1 for all b.
    # number of rows is \sum(l = 0 to L-1) {Mbl}
    allPi <- c(piInfo[[1]], 0, 0, 1, 0)

    # allMu holds the mean vectors for each configuration in each row, number of columns is K
    allMu <- rep(0, K)

    # loop through possible values of bl
    for (b_it in 1:B) {

      # Hmat rows with this bl
      tempH <- Hmat %>% filter(bl == b_it)

      # loop through possible m for this value of bl
      for (m_it in 1:MbVec[b_it + 1]) {
        allPi <- rbind(allPi, cbind(rep(piInfo[[b_it + 1]][m_it] / (2^tempH$sl[1]), nrow(tempH)), tempH$bl,
                                    tempH$sl, rep(m_it, nrow(tempH)), tempH$l))

        for (h_it in 1:nrow(tempH)) {
          allMu <- cbind(allMu, unlist(tempH %>% select(-bl, -sl, -l) %>% slice(h_it)) * muInfo[[b_it + 1]][, m_it])
        }
      } # done looping through different m
    } # dont looping through bl
    colnames(allPi) <- c("Prob", "bl", "sl", "m", "l")

    ##############################################################################################
    # this is the E step where we calculate Pr(Z|c_l,m) for all c_l,m.
    # each l,m is one column.
    # only independence case for now
    conditionalMat <- sapply(X=data.frame(allMu), FUN=calc_dens_ind_2d, Zmat = testStats) %>%
      sweep(., MARGIN=2, STATS=allPi[, 1], FUN="*")
    probZ <- apply(conditionalMat, 1, sum)
    AikMat <- conditionalMat %>% sweep(., MARGIN=1, STATS=probZ, FUN="/")
    Aik_alln <- apply(AikMat, 2, sum) / n

    ###############################################################################################
    # this is the M step for probabilities of hypothesis space
    for (b_it in 0:B) {
      for (m_it in 1:MbVec[b_it + 1]) {
        tempIdx <- which(allPi[, 2] == b_it & allPi[, 4] == m_it)
        piInfo[[b_it + 1]][m_it] <- sum(Aik_alln[tempIdx])
      }
    }

    # M step for the means
    # loop through values of bl
    # do the alternative first
    for (b_it in B:1) {

      tempHmat <- Hmat %>% filter(bl == b_it)
      # loop through m
      for (m_it in 1:MbVec[b_it + 1]) {
        tempMuSum <- rep(0, nrow(allMu))
        tempDenom <- rep(0, nrow(allMu))

        # these are the classes that contribute to \mu_bl,m
        AikIdx <- which(allPi[, 2] == b_it & allPi[, 4] == m_it)
        for (idx_it in 1:length(AikIdx)) {
          tempAik <- AikIdx[idx_it]
          tempHvec <- tempHmat %>% select(-bl, -sl, -l) %>% slice(idx_it) %>% unlist(.)

          tempMuSum <- tempMuSum + colSums(AikMat[, tempAik] * sweep(x = allZ, MARGIN = 2,
                                                                     STATS = tempHvec, FUN="*"))
          tempDenom <- tempDenom + rep(J * Aik_alln[tempAik], length(tempDenom)) * abs(tempHvec)
        } # done looping for one l, m
        whichZero <- which(tempDenom == 0)
        tempDenom[whichZero] <- 1
        muInfo[[b_it + 1]][, m_it] <- tempMuSum / tempDenom

        # make sure mean constraint is satisfied
        if (b_it < B) {
          whichLarger <- which(muInfo[[b_it + 1]][, m_it] > maxMeans)
          if (length(whichLarger) > 0) {
            muInfo[[b_it + 1]][whichLarger, m_it] <- maxMeans[whichLarger]
          }
        } # done with mean constraint

      } # done looping through m

      # set the max means
      if (b_it == B) {
        maxMeans <- apply(muInfo[[b_it + 1]], 1, min)
      }
    } # done updating means

    ###############################################################################################
    # find difference
    allParams <- c(unlist(piInfo), unlist(muInfo))
    diffParams <- sum((allParams - oldParams)^2)

    # update
    oldParams <- allParams
    iter <- iter + 1
    cat(iter, " - ", diffParams, "\n", allParams, "\n")
  }

  # calculate local fdrs
  nullCols <- which(allPi[, 3] < K)
  probNull <- apply(conditionalMat[, nullCols], 1, sum)
  lfdrResults <- probNull / probZ

  return(list(piInfo = piInfo, muInfo = muInfo, iter = iter,
              lfdrResults = lfdrResults, diffParms = diffParams))
}


# apply this function to check over each quadrant
find_2d <- function(x, allTestStats) {
  length(which(allTestStats[1:x, 1] < allTestStats[x, 1] & allTestStats[1:x, 2] < allTestStats[x, 2]))
}
find_3d <- function(x, numRows, allTestStats) {
  length(which(allTestStats[1:x, 1] < allTestStats[x, 1] & allTestStats[1:x, 2] < allTestStats[x, 2] &
                 allTestStats[1:x, 3] < allTestStats[x, 3]))
}

# check to make sure that there are no incongruous results
check_incongruous <- function(zMatrix, lfdrVec) {

  # remove lfdr = 1
  lessThanOne <- which(lfdrVec < 0.99)
  zMatrix <- zMatrix[lessThanOne, ]
  lfdrVec <- lfdrVec[lessThanOne]

  # do it in K^2 quadrants
  K <- ncol(zMatrix)
  quadrants <- expand.grid(rep(list(c(-1, 1)), K))

  badIdx <- c()
  for (quad_it in 1:nrow(quadrants)) {
    # separate into quadrants
    idxVec <- 1:nrow(zMatrix)
    tempStats <- zMatrix
    tempLfdr <- lfdrVec
    for (k_it in 1:K) {
      if (class(tempStats) == "numeric") {break}
      if (quadrants[quad_it, k_it] == -1) {
        toKeep <- which(tempStats[, k_it] < 0 )
        idxVec <- idxVec[toKeep]
        tempLfdr <- tempLfdr[toKeep]
      } else {
        toKeep <- which(tempStats[, k_it] > 0 )
        idxVec <- idxVec[toKeep]
        tempLfdr <- tempLfdr[toKeep]
      }
      tempStats <- tempStats[toKeep, ]
    } # end finding quadrant
    if (length(idxVec) < 1) {next}
    # take absolute value
    tempStats <- abs(tempStats)

    # order by lfdr
    newOrder <- order(tempLfdr)
    tempStats <- tempStats[newOrder, ]
    tempLfdr <- tempLfdr[newOrder]
    idxVec <- idxVec[newOrder]

    # check for incongruous
    if (K == 2) {
      incongruousVec <- sapply(1:nrow(tempStats),FUN = find_2d,  allTestStats = tempStats)
    } else if (K == 3) {
      incongruousVec <- sapply(1:nrow(tempStats), FUN = find_3d, allTestStats = tempStats)
    } else {
      error("only support for 2-3 dimensions right now")
    }

    # get the bad indices
    badIdx <- c(badIdx, idxVec[which(incongruousVec > 0)])
  }

  return(badIdx)
}


#########################################################################################
# function to plot findings
plot_findings <- function(testStatistics, lfdrVec, cutoff, numPts = 20000, plotPDF = FALSE,
                          xlimits=c(-10, 10), ylimits=c(-10, 10), plotPts=NULL) {

  # arrange data
  plotDat <- testStatistics %>% as.data.frame(.) %>%
    set_colnames(paste0("Z", 1:ncol(testStatistics))) %>%
    mutate(lfdr = lfdrVec) %>%
    mutate(idx = 1:nrow(.)) %>%
    arrange(lfdr) %>%
    mutate(LfdrAvg = cummean(lfdr))

  if (!is.null(plotPts)) {
    plotDat <- plotDat %>% filter(idx %in% plotPts)
  } else {
    plotDat <- plotDat %>% slice_sample(n=numPts)
  }

  # significant by running average or straight localfdr?
  if (plotPDF) {
    plotDat <- plotDat %>% mutate(Sig = ifelse(lfdr < cutoff, 1, 0))
  } else {
    plotDat <- plotDat %>% mutate(Sig = ifelse(LfdrAvg < cutoff, 1, 0))
  }

  # plot
  returnPlot <- ggplot(data=plotDat, aes(x = Z1, y=Z2, color=as.factor(Sig))) +
    geom_point() +
    geom_hline(yintercept = 0) +
    geom_vline(xintercept = 0) +
    theme_cowplot() +
    xlim(xlimits) + ylim(ylimits) +
    scale_color_manual(name = "Significant", values = c("#F8766D", "#00BFC4"), labels = c("FALSE", "TRUE"))

  return(returnPlot)
}



################################################################################
# now correlated data


# apply this function to calculate the density for correlated case
calc_dens_cor <- function(x, Zmat, corMat) {
  # right now, only for 2 or 3 dimensions
  # will do each row of Zmat separately
  mvtnorm::dmvnorm(Zmat, mean=x, sigma = corMat)
}

# testStats is J*K matrix of test statistics
# initMuList is list of length K - 1, where the bth element of the list is a K*Mb matrix with the
# means for bl = b
# initPiList is a list of length K, where the bth element of the list is an Mb*1 vector holding
# the probabilities for bl = b
# RIGHT NOW THIS ONLY DOES 2D DUE TO THE R^-1L PART
symm_fit_cor <- function(testStats, corMat, initMuList, initPiList, eps = 10^(-5)) {

  sigInv = solve(corMat)
  J <- nrow(testStats)
  # number of dimensions
  K <- ncol(testStats)
  B <- 2^K - 1
  # number of hl configurations - 1
  L <- 3^K - 1
  # make all configurations
  Hmat <- expand.grid(rep(list(-1:1), K))
  # attach the bl
  blVec <- rep(0, nrow(Hmat))
  slVec <- rep(0, nrow(Hmat))
  for (k_it in K:1) {
    blVec <- blVec + 2^(K - k_it) * abs(Hmat[, k_it])
    slVec <- slVec + abs(Hmat[, k_it])
  }
  # sort Hmat
  Hmat <- Hmat %>% mutate(bl = blVec) %>%
    mutate(sl = slVec) %>%
    arrange(blVec, Var1, Var2) %>%
    mutate(l = 0:(nrow(.) - 1))

  # initialize
  # the muInfo and piInfo are lists that hold the information in a more compact manner.
  # the allMu and allPi are matrices that repeat the information so the calculations can be performed faster.
  muInfo <- initMuList
  piInfo <- initPiList
  oldParams <- c(unlist(piInfo), unlist(muInfo))
  MbVec <- sapply(piInfo, FUN=length)

  # run until convergence
  diffParams <- 10
  iter <- 0
  while (diffParams > eps) {

    #####################################################
    # first, update allPi and allMu with the new parameter values

    # allPi holds the probabilities of each configuration (c 1), the bl of that
    # configuration (c 2), the sl of that configuration (c3), the m of that configuration (c 4),
    # and the l of that configuration (c 5),

    # number of rows in piMat is L if Mb = 1 for all b.
    # number of rows is \sum(l = 0 to L-1) {Mbl}
    allPi <- c(piInfo[[1]], 0, 0, 1, 0)

    # allMu holds the mean vectors for each configuration in each row, number of columns is K
    allMu <- rep(0, K)

    # loop through possible values of bl
    for (b_it in 1:B) {

      # Hmat rows with this bl
      tempH <- Hmat %>% filter(bl == b_it)

      # loop through possible m for this value of bl
      for (m_it in 1:MbVec[b_it + 1]) {
        allPi <- rbind(allPi, cbind(rep(piInfo[[b_it + 1]][m_it] / (2^tempH$sl[1]), nrow(tempH)), tempH$bl,
                                    tempH$sl, rep(m_it, nrow(tempH)), tempH$l))

        for (h_it in 1:nrow(tempH)) {
          allMu <- cbind(allMu, unlist(tempH %>% select(-bl, -sl, -l) %>% slice(h_it)) * muInfo[[b_it + 1]][, m_it])
        }
      } # done looping through different m
    } # dont looping through bl
    colnames(allPi) <- c("Prob", "bl", "sl", "m", "l")

    ##############################################################################################
    # this is the E step where we calculate Pr(Z|c_l,m) for all c_l,m.
    # each l,m is one column.
    # only independence case for now
    conditionalMat <- sapply(X=data.frame(allMu), FUN=calc_dens_cor, Zmat = testStats, corMat = corMat) %>%
      sweep(., MARGIN=2, STATS=allPi[, 1], FUN="*")
    probZ <- apply(conditionalMat, 1, sum)
    AikMat <- conditionalMat %>% sweep(., MARGIN=1, STATS=probZ, FUN="/")
    Aik_alln <- apply(AikMat, 2, sum) / n

    ###############################################################################################
    # this is the M step for probabilities of hypothesis space
    for (b_it in 0:B) {
      for (m_it in 1:MbVec[b_it + 1]) {
        tempIdx <- which(allPi[, 2] == b_it & allPi[, 4] == m_it)
        piInfo[[b_it + 1]][m_it] <- sum(Aik_alln[tempIdx])
      }
    }

    # M step for the means
    # loop through values of bl
    # do the alternative first
    for (b_it in B:1) {

      tempHmat <- Hmat %>% filter(bl == b_it)
      # loop through m
      for (m_it in 1:MbVec[b_it + 1]) {
        tempRightSum <- rep(0, nrow(allMu))
        tempLeftSum <- rep(0, nrow(allMu))

        # these are the classes that contribute to \mu_bl,m
        AikIdx <- which(allPi[, 2] == b_it & allPi[, 4] == m_it)
        for (idx_it in 1:length(AikIdx)) {
          tempAik <- AikIdx[idx_it]
          tempHvec <- tempHmat %>% select(-bl, -sl, -l) %>% slice(idx_it) %>% unlist(.)
          LsigInvL <- diag(tempHvec) %*% sigInv %*% diag(tempHvec)

          tempLeftSum <- tempLeftSum + colSums(AikMat[, tempAik] * sweep(x = allZ %*% sigInv, MARGIN = 2,
                                                                     STATS = tempHvec, FUN="*"))
          tempRightSum <- tempRightSum + rep(J * Aik_alln[tempAik], length(tempDenom)) * LsigInvL
        } # done looping for one l, m

        # matrix inverse only for alternative
        if (b_it == B) {
          muInfo[[b_it + 1]][, m_it] <- solve(tempRightSum) %*% tempLeftSum
        } else {
          whichZero <- which(diag(tempRightSum) == 0)
          tempRightSum[whichZero, whichZero] <- 1
          muInfo[[b_it + 1]][, m_it] <- tempLeftSum / diag(tempRightSum)
        }

        # make sure mean constraint is satisfied
        if (b_it < B) {
          whichLarger <- which(muInfo[[b_it + 1]][, m_it] > maxMeans)
          if (length(whichLarger) > 0) {
            muInfo[[b_it + 1]][whichLarger, m_it] <- maxMeans[whichLarger]
          }
        } # done with mean constraint

      } # done looping through m

      # set the max means
      if (b_it == B) {
        maxMeans <- apply(muInfo[[b_it + 1]], 1, min)
      }
    } # done updating means

    ###############################################################################################
    # find difference
    allParams <- c(unlist(piInfo), unlist(muInfo))
    diffParams <- sum((allParams - oldParams)^2)

    # update
    oldParams <- allParams
    iter <- iter + 1
    cat(iter, " - ", diffParams, "\n", allParams, "\n")
  }

  # calculate local fdrs
  nullCols <- which(allPi[, 3] < K)
  probNull <- apply(conditionalMat[, nullCols], 1, sum)
  lfdrResults <- probNull / probZ

  return(list(piInfo = piInfo, muInfo = muInfo, iter = iter,
              lfdrResults = lfdrResults, diffParms = diffParams))
}


# true model - Mb = 2 for the single association cases, otherwise Mb = 1
piList <- list(c(0.82), c(0.02, 0.02), c(0.02, 0.02), c(0.1))
muList <- list(matrix(data=0, nrow=2, ncol=1), matrix(data=c(0, 2, 0, 4), nrow=2),
               matrix(data=c(2, 0, 4, 0), nrow=2), matrix(data=c(6, 6), nrow=2))
n <- 200000
trueSig <- matrix(data=c(1, 0.4, 0.4, 1), nrow=2)

set.seed(0)
Z0 <- rmvnorm(n=n * piList[[1]], mean=c(0, 0), sigma=trueSig)
Z1_m1 <- rbind(rmvnorm(n=n * piList[[2]][1] / 2, mean=c(0, muList[[2]][2, 1]), sigma=trueSig),
               rmvnorm(n=n * piList[[2]][1] / 2, mean=c(0, -muList[[2]][2, 1]), sigma=trueSig))
Z1_m2 <- rbind(rmvnorm(n=n * piList[[2]][2] / 2, mean=c(0, muList[[2]][2, 2]), sigma=trueSig),
               rmvnorm(n=n * piList[[2]][2] / 2, mean=c(0, -muList[[2]][2, 2]), sigma=trueSig))
Z2_m1 <- rbind(rmvnorm(n=n * piList[[3]][1] / 2, mean=c(muList[[3]][1, 1], 0), sigma=trueSig),
               rmvnorm(n=n * piList[[3]][1] / 2, mean=c(-muList[[3]][1, 1], 0), sigma=trueSig))
Z2_m2 <- rbind(rmvnorm(n=n * piList[[3]][2] / 2, mean=c(muList[[3]][1, 2], 0), sigma=trueSig),
               rmvnorm(n=n * piList[[3]][2] / 2, mean=c(-muList[[3]][1, 2], 0), sigma=trueSig))
Z3 <- rbind(rmvnorm(n=n * piList[[4]][1] / 4, mean=c(muList[[4]][1, 1], muList[[4]][2, 1]), sigma=trueSig),
            rmvnorm(n=n * piList[[4]][1] / 4, mean=c(muList[[4]][1, 1], -muList[[4]][2, 1]), sigma=trueSig),
            rmvnorm(n=n * piList[[4]][1] / 4, mean=c(-muList[[4]][1, 1], muList[[4]][2, 1]), sigma=trueSig),
            rmvnorm(n=n * piList[[4]][1] / 4, mean=c(-muList[[4]][1, 1], -muList[[4]][2, 1]), sigma=trueSig))
allZ <- rbind(Z0, Z1_m1, Z1_m2, Z2_m1, Z2_m2, Z3)
testStats <- allZ

apply(Z0, 2, mean)
apply(abs(Z1_m1), 2, mean)
apply(abs(Z1_m2), 2, mean)
apply(abs(Z2_m1), 2, mean)
apply(abs(Z2_m2), 2, mean)
apply(abs(Z3), 2, mean)

# give it the real parameters - works
initMuList <- muList
initPiList <- piList
outputCor <- symm_fit_cor(testStats = allZ, corMat = trueSig,
                           initMuList = initMuList, initPiList = initPiList, eps=10^(-5))
# check for incongruous - will be some
# remember that we're only good in the tail
incongruousCor <- check_incongruous(zMatrix = allZ[1:200000, ], lfdrVec = outputCor$lfdrResults[1:200000])

# plot
plot_findings(testStatistics = allZ, lfdrVec = outputCor$lfdrResults, cutoff = 0.01,
              numPts = 20000, plotPDF = TRUE)


# give it a harder test
set.seed(1)
maxMeans <- matrix(data=runif(n=2, min=4, max=8), nrow=2, ncol=1)
initMuList <- list(matrix(data=0, nrow=2, ncol=1), matrix(data=runif(n=4, min=0, max=min(maxMeans)), nrow=2, ncol=2),
                   matrix(data=runif(n=4, min=0, max=min(maxMeans)), nrow=2, ncol=2), maxMeans)
initMuList
initPiList <- list(c(0.82), c(0.02, 0.02),c(0.02, 0.02), c(0.1))

# run it - takes some time, goes down up down, but converges in 152 iterations to approximately the right thing
outputCorHard <- symm_fit_cor(testStats = allZ,  corMat = trueSig,
                           initMuList = initMuList, initPiList = initPiList, eps=10^(-5))
incongruousCorHard <- check_incongruous(zMatrix = allZ, lfdrVec = outputCorHard$lfdrResults)

# plot
set.seed(1)
plotPts <- sample(1:200000, size=20000)
plot_findings(testStatistics = allZ, lfdrVec = outputCorHard$lfdrResults, cutoff = 0.01,
              numPts = 20000, plotPDF = TRUE, plotPts = plotPts)

# try old method
source("/users/rsun3/box/aaawork/research/empbayesmed/2022-04-10/calc_cond_pmfs.R")
source("/users/rsun3/box/aaawork/research/empbayesmed/2022-04-10/define_H_space.R")
source("/users/rsun3/box/aaawork/research/empbayesmed/2022-04-10/emp_bayes_framework_new.R")
source("/users/rsun3/box/aaawork/research/empbayesmed/2022-04-10/locfdr_estim.R")
oldOutput <- emp_bayes_framework(summary_tab = allZ, q_threshold = 0.1, Hdist_epsilon=10^(-4), checkpoint=TRUE)


# plot results
plot_findings(testStatistics = allZ, lfdrVec = oldOutput$lfdrVec, cutoff = 0.01,
              numPts = 20000, plotPDF = TRUE, plotPts = plotPts)


# give it heart disease and lung cancer

# look at the estimated density
